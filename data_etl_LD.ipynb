{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a431bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "# data analysis and wrangling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from metpy import calc\n",
    "from datetime import datetime, timedelta\n",
    "from statistics import mean\n",
    "\n",
    "# visualization\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7efd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas options\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5165f3c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (Temp/ipykernel_2852/2249592806.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\lesli\\AppData\\Local\\Temp/ipykernel_2852/2249592806.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    raw_df[file[:-4]] = pd.read_csv(os.path.join(os.getcwd(), 'data', file)\u001b[0m\n\u001b[1;37m                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Read data files\n",
    "\n",
    "data_files = ['train.csv', 'test.csv', 'weather_train.csv', 'weather_test.csv', 'building_metadata.csv']\n",
    "raw_df = {}\n",
    "\n",
    "for file in data_files:\n",
    "    raw_df[file[:-4]] = pd.read_csv(os.path.join(os.getcwd(), 'data', file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390485b",
   "metadata": {},
   "source": [
    "# Classifying\n",
    "We may want to classify or categorize our samples. We may also want to understand the implications or correlation of different classes with our solution goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bca6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to examine and return missing data from a dataframe as a percentage\n",
    "\n",
    "def missingdata(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    ms=pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    ms= ms[ms[\"Percent\"] > 0]\n",
    "\n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc6757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "\n",
    "# Train & Test data\n",
    "\n",
    "train_df = raw_df['train'].copy()\n",
    "test_df = raw_df['test'].copy()\n",
    "\n",
    "train_df.info(verbose=True, show_counts=True)\n",
    "print('-'*40)\n",
    "test_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd851956",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189761b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather train & Weather test data\n",
    "\n",
    "weather_train_df = raw_df['weather_train'].copy()\n",
    "weather_test_df = raw_df['weather_test'].copy()\n",
    "\n",
    "weather_train_df.info(verbose=True, show_counts=True)\n",
    "print('-'*40)\n",
    "weather_test_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(weather_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(weather_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c73e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building metadata\n",
    "\n",
    "building_df = raw_df['building_metadata'].copy()\n",
    "\n",
    "building_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda483b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(building_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ea9b6",
   "metadata": {},
   "source": [
    "# Charting\n",
    "How to select the right visualization plots and charts depending on nature of the data and the solution goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec4a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9a377e7",
   "metadata": {},
   "source": [
    "# Correcting\n",
    "We may also analyze the given training dataset for errors or possibly inaccurate values within features and try to correct these values or exclude the samples containing the errors. One way to do this is to detect any outliers among our samples or features. We may also completely discard a feature if it is not contributing to the analysis or may significantly skew the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7988e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting by dropping features with a lot of missing data\n",
    "\n",
    "weather_drop = ['cloud_coverage', 'precip_depth_1_hr', 'sea_level_pressure']\n",
    "building_drop = ['floor_count', 'year_built']\n",
    "\n",
    "weather_train_df.drop(weather_drop, axis=1, inplace=True)\n",
    "weather_test_df.drop(weather_drop, axis=1, inplace=True)\n",
    "building_df.drop(building_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132baf94",
   "metadata": {},
   "source": [
    "# Completing\n",
    "Data preparation may also require us to estimate any missing values within a feature. Model algorithms may work best when there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9171ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate weather null values based on the averages of \n",
    "# the previous and post known values\n",
    "\n",
    "def estimate_weather(df, col):\n",
    "    null_dex = list(df.loc[df[col].isna()]['timestamp'].index)\n",
    "    for dex in null_dex:\n",
    "        if math.isnan(df[col][dex+1]):\n",
    "            df[col][dex] = df[col][dex-1].copy()\n",
    "        else:\n",
    "            df[col][dex] = round(mean([df[col][dex-1],df[col][dex+1]]), 1).copy()\n",
    "    return df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating the values for weather data using the average from the previous & following hour\n",
    "\n",
    "weather_combined = [weather_train_df, weather_test_df]\n",
    "col_to_complete = ['wind_direction', 'wind_speed', 'dew_temperature', 'air_temperature']\n",
    "\n",
    "for w_df in weather_combined:\n",
    "    for c in col_to_complete:\n",
    "        w_df[c] = estimate_weather(w_df, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a9f4b",
   "metadata": {},
   "source": [
    "# Creating\n",
    "Can we create new features based on an existing feature or a set of features, such that the new feature follows the correlation, conversion, completeness goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new humidity feature calculated from air & dew temperature\n",
    "\n",
    "# Calculation formula source: https://www.weather.gov/media/epz/wxcalc/vaporPressure.pdf\n",
    "\n",
    "weather_combined = [weather_train_df, weather_test_df]\n",
    "\n",
    "for w_df in weather_combined:\n",
    "    rh_list = []\n",
    "    for i in range(0,len(w_df)):\n",
    "        e_s = 6.11 * 10 * ((7.5 * w_df['air_temperature'][i])/(237.3 + w_df['air_temperature'][i]))\n",
    "        e = 6.11 * 10 * ((7.5 * w_df['dew_temperature'][i])/(237.3 + w_df['dew_temperature'][i]))\n",
    "\n",
    "        rh_list.append(round(e / e_s * 100, 1))\n",
    "    w_df['relative_humidity'] = rh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c703955",
   "metadata": {},
   "outputs": [],
   "source": [
    "metpy.calc.relative_humidity_from_dewpoint(['18'], ['15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307811f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_combined = [weather_train_df, weather_test_df]\n",
    "\n",
    "for w_df in weather_combined:\n",
    "    rh = metpy.calc.relative_humidity_from_dewpoint(str(w_df['air_temperature'][0]), str(w_df['dew_temperature'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16df3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a52c330c",
   "metadata": {},
   "source": [
    "# Converting\n",
    "For modeling stage, one needs to prepare the data. Depending on the choice of model algorithm one may require all features to be converted to numerical equivalent values. So for instance converting text categorical values to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting timestamp from object to datetime\n",
    "\n",
    "combined = [train_df, test_df, weather_train_df, weather_test_df]\n",
    "\n",
    "for df in combined:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping primary_use category in building metadata\n",
    "\n",
    "primary_use_map = {'Education': 1, 'Office': 2, 'Entertainment/public assembly': 3, 'Lodging/residential': 4,\n",
    "                   'Public services': 5, 'Healthcare': 6, 'Other': 7, 'Parking': 8, 'Manufacturing/industrial': 9,\n",
    "                   'Food sales and service': 10, 'Retail': 11, 'Warehouse/storage': 12, 'Services': 13, \n",
    "                   'Technology/science': 14, 'Utility': 15, 'Religious worship': 16}\n",
    "\n",
    "building_df['primary_use'] = building_df['primary_use'].map(primary_use_map).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc42b8dd",
   "metadata": {},
   "source": [
    "# Correlating\n",
    "One can approach the problem based on available features within the training dataset. Which features within the dataset contribute significantly to our solution goal? Statistically speaking is there a correlation among a feature and solution goal? As the feature values change does the solution state change as well, and visa-versa? This can be tested both for numerical and categorical features in the given dataset. We may also want to determine correlation among features other than survival for subsequent goals and workflow stages. Correlating certain features may help in creating, completing, or correcting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c21376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "\n",
    "train_merged = train_df.merge(building_df, on='building_id', how='left')\n",
    "train_merged = train_merged.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "test_merged = test_df.merge(building_df, on='building_id', how='left')\n",
    "test_merged = test_merged.merge(weather_test_df, on=['site_id', 'timestamp'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab99d325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20daa6aa",
   "metadata": {},
   "source": [
    "# Model, predict and solve\n",
    "Now we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We are also performing a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce571fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
